{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information_from_json(json_data=\"\"):\n",
    "    \"\"\"\n",
    "    Process JSON data to extract structured text information.\n",
    "\n",
    "    Args:\n",
    "        json_data (dict): The JSON data extracted from the ZIP file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Structured data grouped by sections.\n",
    "    \"\"\"\n",
    "\n",
    "    datas = json_data[\"elements\"]\n",
    "\n",
    "    # Initialize variables\n",
    "    header = None\n",
    "    sub_header = None\n",
    "    value = []\n",
    "    structured_data = {}\n",
    "\n",
    "    combined_empty_sections = []\n",
    "    heading_count = 0\n",
    "\n",
    "    unmatched_texts = []\n",
    "\n",
    "    for element in datas:\n",
    "        path = element.get(\"Path\", \"\")\n",
    "        text = element.get(\"Text\", \"\").strip()\n",
    "        # text = preprocess_pipeline(text)\n",
    "        # Ignore references and footnotes\n",
    "        if '/Footnote' in path:\n",
    "            continue\n",
    "\n",
    "        # Handle headers (Title, H1, H2)\n",
    "        elif '/Title' in path:\n",
    "            # Combine empty sections into HEADING_X if previous sections were empty\n",
    "            if not value and combined_empty_sections:\n",
    "                heading_count += 1\n",
    "                combined_title = f\"HEADING_{heading_count}\"\n",
    "                structured_data[combined_title] = combined_empty_sections\n",
    "                combined_empty_sections = []\n",
    "\n",
    "            # Start a new header\n",
    "            header = text\n",
    "            sub_header = None\n",
    "            if header not in structured_data:\n",
    "                structured_data[header] = []\n",
    "\n",
    "        elif \"/H1\" in path or (\"/H2\" in path and \"/Figure\" not in path):\n",
    "            # print(\"text: \", text)\n",
    "            if value:\n",
    "                # Append accumulated content to the current section\n",
    "                if sub_header:\n",
    "                    structured_data[header].append(\n",
    "                        {sub_header: \" \".join(value)})\n",
    "                else:\n",
    "                    structured_data[header].append(\" \".join(value))\n",
    "                value = []\n",
    "\n",
    "            # Update header and sub_header\n",
    "            if \"/H1\" in path:\n",
    "                header = text if text else \"Untitled Section\"\n",
    "                if header not in structured_data:\n",
    "                    structured_data[header] = []\n",
    "                sub_header = None\n",
    "            if \"/H2\" in path:\n",
    "                sub_header = text if text else \"Untitled Subsection\"\n",
    "                # print(\"text\", text)\n",
    "            else:\n",
    "                structured_data[text] = []\n",
    "\n",
    "        # Handle paragraphs and other text\n",
    "        elif text:\n",
    "            if header and not structured_data.get(header, []):\n",
    "                # Initialize header with text\n",
    "                structured_data[header] = [text]\n",
    "            elif header:\n",
    "                value.append(text)\n",
    "            else:\n",
    "                unmatched_texts.append(text)\n",
    "\n",
    "    # Add the last accumulated data\n",
    "    if value or header or sub_header:\n",
    "        if header:\n",
    "            if sub_header:\n",
    "                if value:\n",
    "                    structured_data[header].append(\n",
    "                        {sub_header: \" \".join(value)})\n",
    "                else:\n",
    "                    structured_data[header] = sub_header\n",
    "            else:\n",
    "                structured_data[header].append(\" \".join(value))\n",
    "        value = []\n",
    "\n",
    "    # Combine remaining empty sections if any\n",
    "    if combined_empty_sections:\n",
    "        heading_count += 1\n",
    "        combined_title = f\"HEADING_{heading_count}\"\n",
    "        structured_data[combined_title] = combined_empty_sections\n",
    "\n",
    "    # Combine unmatched texts into \"Other\"\n",
    "    combined_key = \"Other\"\n",
    "    combined_data = {combined_key: unmatched_texts}\n",
    "\n",
    "    for key, value in structured_data.items():\n",
    "        if isinstance(value, list) and not value:  # Empty lists\n",
    "            combined_data[combined_key].append(key)\n",
    "        else:\n",
    "            combined_data[key] = value\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"../backend/output/ExtractTextInfoFromPDF/extract2024-12-13T01-19-16/structuredData.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "output = extract_information_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other': ['ABHISHEK PANDEY',\n",
       "  'abhi526691shek@gmail.com',\n",
       "  'Linkedin',\n",
       "  'Github',\n",
       "  'Hackerrank',\n",
       "  '20 doerr rd, M1P 3A1, ON (5*)'],\n",
       " 'Experience': ['Jan 2022 - Sept 2023',\n",
       "  {'FullStack Generative AI Developer': 'Dimensionless Technologies, Remote ● AUSHADHAI Built and deployed the reconciliation feature within , automating data alignment and discrepancy resolution across pharmacy systems, reducing reconciliation time by 40%. ● Developed scalable backend APIs using Django, integrated with AWS and Azure databases, resulting in a 35% improvement in system performance and data processing efficiency. ● PROPELPRO Led the automation of document processing and image recognition tasks in with AI-driven solutions, achieving a 40% increase in processing efficiency and contributing to 20% revenue growth through improved client deliverables. ● Designed pipelines for Q&A and summarization,leveraging Generative AI to improve large document analysis, enhancing user productivity by 30% and ensuring scalability for data solutions.'},\n",
       "  {'Associate Software Engineer Intern': 'Feb 2021 - Nov 2021 Ameex Technologies PVT LTD Chennai, TamilNadu, IN ● Developed and tested RESTful APIs to enhance backend functionality and streamline data management for client applications, ensuring seamless user interactions. ● Designed user-centric interfaces and performed comprehensive testing to ensure optimal UI/UX, focusing on improving user satisfaction and application reliability.'}],\n",
       " 'Skills': ['FullStack: HTML, CSS, React.js, Flask, Django, Nodejs, JS, Java, C, C++',\n",
       "  'ML Ops/DevOps: AWS, Azure, Docker, Github, Jenkins, Terraforms, Ansible, Kubernates Data Engineering: Python, Apache Spark, Hadoop, SQL, Mongodb, Cassandra, Redis, Chromadb AI/ML: PyTorch, Tensorflow, AWS Sagemaker, Azure Cognitive Service, Spark MLib Scikit-learn, keras, Fine-Tuning LLM Models, Transfer Learning.'],\n",
       " 'Projects': ['July 2023 ● Built an advanced research paper analysis tool that allows users to upload PDFs of any length, generating detailed section-wise summaries and enabling Q&A functionality using OpenAI embeddings.',\n",
       "  {'ResearchIQ | OpenAI, Django, React, Pinecone, Adobe Pdf Services': '● Leveraged Adobe PDF services and OpenAI APIs to extract and process PDF content into CSV format, achieving a 50% improvement in summarization and Q&A efficiency, and delivering in-depth document insights.'},\n",
       "  {'AuthentiScan|Selenium, VGG-Net, ResNet, MtCNN, AWS, python': 'Jan 2024 ● Developed a high-accuracy DeepFake image detector that identifies real versus fake images, leveraging VGG-Face and ResNet-50 models, with training data scraped from live sources (Pexels, Unsplash, freepix, ThisPersonDoesNotExist). ● Achieved 98% accuracy by integrating advanced image processing models (VGG-Net, ResNet, and MtCNN) on AWS, creating a reliable and scalable solution for real-time image authentication.'}],\n",
       " 'Education': ['Ontario College Graduate Certificate in AI and Data Science(3.4/4.0 GPA)',\n",
       "  {'Loyalist College': 'North york, ON, CAN'},\n",
       "  {'Vel Tech Rangarajan Dr Sagunthala R&D University': 'Bachelor in Technology, Computer Science and Engineering(4.0/4.0 GPA)'}],\n",
       " 'Achievements': ['Chennai, TamilNadu, IN',\n",
       "  'D2C Chief Igniter - Unstop: Streamlined the approval process for campus events, competitions, and workshops, accelerating event execution and enhancing campus engagement. Winner of First Place at Prakalpa Z-20 Online Project Contest for the AI-driven project \"DESTROY COVID-19,\" organized by collaboration of Vel Tech and the Computer Society of India (CSI).'],\n",
       " 'Certifications': 'PCAP:programming essentials in python by CISCO, Deep learning by NPTEL, Data Analysis with Python by Cognitive Class, Deep Learning.ai by Andrew Ng, Hadoop Foundations - Level 1 by IBM'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other': 'ABHISHEK PANDEY, abhi526691shek@gmail.com, Linkedin, Github, Hackerrank, 20 doerr rd, M1P 3A1, ON (5*)',\n",
       " 'Experience': 'Jan 2022 - Sept 2023, FullStack Generative AI Developer: Dimensionless Technologies, Remote ● AUSHADHAI Built and deployed the reconciliation feature within , automating data alignment and discrepancy resolution across pharmacy systems, reducing reconciliation time by 40%. ● Developed scalable backend APIs using Django, integrated with AWS and Azure databases, resulting in a 35% improvement in system performance and data processing efficiency. ● PROPELPRO Led the automation of document processing and image recognition tasks in with AI-driven solutions, achieving a 40% increase in processing efficiency and contributing to 20% revenue growth through improved client deliverables. ● Designed pipelines for Q&A and summarization,leveraging Generative AI to improve large document analysis, enhancing user productivity by 30% and ensuring scalability for data solutions., Associate Software Engineer Intern: Feb 2021 - Nov 2021 Ameex Technologies PVT LTD Chennai, TamilNadu, IN ● Developed and tested RESTful APIs to enhance backend functionality and streamline data management for client applications, ensuring seamless user interactions. ● Designed user-centric interfaces and performed comprehensive testing to ensure optimal UI/UX, focusing on improving user satisfaction and application reliability.',\n",
       " 'Skills': 'FullStack: HTML, CSS, React.js, Flask, Django, Nodejs, JS, Java, C, C++, ML Ops/DevOps: AWS, Azure, Docker, Github, Jenkins, Terraforms, Ansible, Kubernates Data Engineering: Python, Apache Spark, Hadoop, SQL, Mongodb, Cassandra, Redis, Chromadb AI/ML: PyTorch, Tensorflow, AWS Sagemaker, Azure Cognitive Service, Spark MLib Scikit-learn, keras, Fine-Tuning LLM Models, Transfer Learning.',\n",
       " 'Projects': 'July 2023 ● Built an advanced research paper analysis tool that allows users to upload PDFs of any length, generating detailed section-wise summaries and enabling Q&A functionality using OpenAI embeddings., ResearchIQ | OpenAI, Django, React, Pinecone, Adobe Pdf Services: ● Leveraged Adobe PDF services and OpenAI APIs to extract and process PDF content into CSV format, achieving a 50% improvement in summarization and Q&A efficiency, and delivering in-depth document insights., AuthentiScan|Selenium, VGG-Net, ResNet, MtCNN, AWS, python: Jan 2024 ● Developed a high-accuracy DeepFake image detector that identifies real versus fake images, leveraging VGG-Face and ResNet-50 models, with training data scraped from live sources (Pexels, Unsplash, freepix, ThisPersonDoesNotExist). ● Achieved 98% accuracy by integrating advanced image processing models (VGG-Net, ResNet, and MtCNN) on AWS, creating a reliable and scalable solution for real-time image authentication.',\n",
       " 'Education': 'Ontario College Graduate Certificate in AI and Data Science(3.4/4.0 GPA), Loyalist College: North york, ON, CAN, Vel Tech Rangarajan Dr Sagunthala R&D University: Bachelor in Technology, Computer Science and Engineering(4.0/4.0 GPA)',\n",
       " 'Achievements': 'Chennai, TamilNadu, IN, D2C Chief Igniter - Unstop: Streamlined the approval process for campus events, competitions, and workshops, accelerating event execution and enhancing campus engagement. Winner of First Place at Prakalpa Z-20 Online Project Contest for the AI-driven project \"DESTROY COVID-19,\" organized by collaboration of Vel Tech and the Computer Society of India (CSI).',\n",
       " 'Certifications': 'PCAP:programming essentials in python by CISCO, Deep learning by NPTEL, Data Analysis with Python by Cognitive Class, Deep Learning.ai by Andrew Ng, Hadoop Foundations - Level 1 by IBM'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_values_to_string(data):\n",
    "    \"\"\"\n",
    "    Convert all values in a dictionary (including nested structures) into a single flattened string.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (dict): The input dictionary with possibly nested or multiple items.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary where values are flattened into strings.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "\n",
    "    def process_value(value):\n",
    "        if isinstance(value, dict):\n",
    "            # Convert dictionary to a single string by joining key-value pairs\n",
    "            return \"; \".join(f\"{k}: {process_value(v)}\" for k, v in value.items())\n",
    "        elif isinstance(value, list):\n",
    "            # Convert list to a single string by joining items\n",
    "            return \", \".join(process_value(v) for v in value)\n",
    "        else:\n",
    "            # Return the value as a string\n",
    "            return str(value)\n",
    "\n",
    "    for key, value in data.items():\n",
    "        result[key] = process_value(value)\n",
    "\n",
    "    return result\n",
    "\n",
    "flatten_values_to_string(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
